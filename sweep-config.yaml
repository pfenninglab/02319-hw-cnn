# sweep-config.yaml: Config for `wandb` hyperparameter sweep.
# Usage: sbatch sweep.sb
#
# Note: To run the sweep in an interactive session (e.g. for debugging),
#     wandb sweep sweep-config.yaml
# This is not recommended for actual training (use sbatch instead).

program: train.py

command:
  - ${env}
  - ${interpreter}
  - ${program}
  - "-config"
  - "config-base.yaml"
  - ${args}

project: test-sweep

method: random

metric:
  goal: minimize
  name: val_loss

early_terminate:
  type: hyperband
  s: 2
  eta: 3
  max_iter: 27

parameters:
  lr_init:
    distribution: log_uniform_values
    min: 1.5e-5
    max: 1.e-2

  lr_exp_decay_per_epoch:
    distribution: uniform
    min: 0.75
    max: 0.98

  num_conv_layers:
    values: [1, 2, 3, 4, 5]

  conv_width:
    values: [3, 5, 7, 9, 11]

  conv_filters:
    values: [50, 100, 200, 300, 500]

  l2_reg:
    distribution: log_uniform_values
    min: 1e-5
    max: 1e-3

  dropout_rate:
    distribution: uniform
    min: 0.0
    max: 0.6
